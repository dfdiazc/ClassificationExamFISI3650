{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Rice_Image_Dataset/Train'\n",
    "batch_size = 64\n",
    "img_height = 50\n",
    "img_width = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 files belonging to 5 classes.\n",
      "Using 40000 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'training',\n",
    "    seed = 42,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 files belonging to 5 classes.\n",
      "Using 10000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'validation',\n",
    "    seed = 42,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\n",
    "      'horizontal',\n",
    "      input_shape=(img_height, img_width, 3)),\n",
    "      tf.keras.layers.RandomRotation(0.1),\n",
    "      tf.keras.layers.RandomZoom(0.1),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # data_augmentation,\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 19:56:58.325606: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-11 19:56:58.330436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 19:57:14.509793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 19s 20ms/step - loss: 0.1298 - accuracy: 0.9521 - val_loss: 0.0724 - val_accuracy: 0.9749\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.0672 - accuracy: 0.9767 - val_loss: 0.0616 - val_accuracy: 0.9792\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.0578 - val_accuracy: 0.9791\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0465 - val_accuracy: 0.9838\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.0342 - accuracy: 0.9881 - val_loss: 0.0359 - val_accuracy: 0.9888\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.0451 - val_accuracy: 0.9841\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0334 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.0396 - val_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0299 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 12s 18ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.0300 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f5ed670>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "[100.   0.   0.   0.   0.]\n",
      " ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
      "Prediction:  Arborio 99.9974012374878%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 20:06:25.624590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "classes = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
    "\n",
    "path = 'Rice_Image_Dataset/Train/Arborio/Arborio (1).jpg'\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(path, target_size=(img_height, img_width)) \n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "print(f\"{(predictions[0]*100).round(2)}\\n\", classes)\n",
    "print(\"Prediction: \", classes[np.argmax(predictions)], f\"{predictions[0][np.argmax(predictions)]*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4743f3265159d618cbfb7986907cf5d87d97b4cb2417375c3879348497beb2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
